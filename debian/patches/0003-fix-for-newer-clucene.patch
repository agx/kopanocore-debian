From: Matthias Geerdsen <matthias@vorlons.info>
Date: Thu, 15 Aug 2013 21:50:10 +0200
Subject: fix for newer clucene

---
 ECtools/zarafa-search/ECAnalyzers.cpp | 16 ++++++++--------
 ECtools/zarafa-search/ECAnalyzers.h   |  5 ++---
 ECtools/zarafa-search/ECIndexDB.cpp   |  4 ++--
 3 files changed, 12 insertions(+), 13 deletions(-)

diff --git a/ECtools/zarafa-search/ECAnalyzers.cpp b/ECtools/zarafa-search/ECAnalyzers.cpp
index de865dc..d08c6e8 100644
--- a/ECtools/zarafa-search/ECAnalyzers.cpp
+++ b/ECtools/zarafa-search/ECAnalyzers.cpp
@@ -79,24 +79,24 @@ EmailFilter::~EmailFilter() {
  * @param token Output token
  * @return false if no more token was available
  */
-bool EmailFilter::next(lucene::analysis::Token *token) {
+lucene::analysis::Token *EmailFilter::next(lucene::analysis::Token *token) {
 	// See if we had any stored tokens
 	if(part < parts.size()) {
 		token->set(parts[part].c_str(), 0, 0, _T("<EMAIL>"));
 		token->setPositionIncrement(0);
 		part++;
-		return true;
+		return token;
 	} else {
 		// No more stored token, get a new one
 		if(!input->next(token))
-			return false;
+			return NULL;
 
 		// Split EMAIL tokens into the various parts
 		if(wcscmp(token->type(), L"<EMAIL>") == 0) {
 			// Split into user, domain, com
-			parts = tokenize((std::wstring)token->_termText, (std::wstring)L".@");
+			parts = tokenize((std::wstring)token->termBuffer(), (std::wstring)L".@");
 			// Split into user, domain.com
-			std::vector<std::wstring> moreparts = tokenize((std::wstring)token->_termText, (std::wstring)L"@");
+			std::vector<std::wstring> moreparts = tokenize((std::wstring)token->termBuffer(), (std::wstring)L"@");
 			parts.insert(parts.end(), moreparts.begin(), moreparts.end());
 			
 			// Only add parts once (unique parts)
@@ -111,7 +111,7 @@ bool EmailFilter::next(lucene::analysis::Token *token) {
 			std::vector<std::wstring> hostparts;
 			
 			// Convert into some-strange.domain.com domain.com com
-			hostparts = tokenize((std::wstring)token->_termText, (std::wstring)L".");
+			hostparts = tokenize((std::wstring)token->termBuffer(), (std::wstring)L".");
 			
 			parts.clear();
 			while(hostparts.size() > 1 && hostparts.size() < 10) { // 10 as a defensive measure against the following blowing up
@@ -122,7 +122,7 @@ bool EmailFilter::next(lucene::analysis::Token *token) {
 			part = 0;
 		}
 		
-		return true;
+		return token;
 	}
 }
 
@@ -141,7 +141,7 @@ ECAnalyzer::~ECAnalyzer()
  * @param reader Reader to read the bytestream to tokenize
  * @return A TokenStream outputting the tokens to be indexed
  */
-lucene::analysis::TokenStream* ECAnalyzer::tokenStream(const TCHAR* fieldName, lucene::util::Reader* reader) 
+lucene::analysis::TokenStream *ECAnalyzer::tokenStream(const TCHAR *fieldName, CL_NS(util)::BufferedReader *reader)
 {
 	lucene::analysis::TokenStream* ret = _CLNEW lucene::analysis::standard::StandardTokenizer(reader);
 	ret = _CLNEW lucene::analysis::standard::StandardFilter(ret,true);
diff --git a/ECtools/zarafa-search/ECAnalyzers.h b/ECtools/zarafa-search/ECAnalyzers.h
index d30162d..96bb237 100644
--- a/ECtools/zarafa-search/ECAnalyzers.h
+++ b/ECtools/zarafa-search/ECAnalyzers.h
@@ -50,7 +50,6 @@
 #ifndef ANALYZERS_H
 
 #include "CLucene/StdHeader.h"
-#include "CLucene/util/Reader.h"
 #include "CLucene/analysis/standard/StandardAnalyzer.h"
 #include "CLucene/analysis/AnalysisHeader.h"
 
@@ -68,7 +67,7 @@ class EmailFilter: public lucene::analysis::TokenFilter {
 public:
 	EmailFilter(lucene::analysis::TokenStream* in, bool deleteTokenStream);
 	virtual ~EmailFilter();
-	bool next(lucene::analysis::Token* token);
+	lucene::analysis::Token *next(lucene::analysis::Token *token);
 private:
 	lucene::analysis::Token curtoken;
 	
@@ -86,7 +85,7 @@ public:
 	ECAnalyzer();
 	virtual ~ECAnalyzer();
 
-	virtual lucene::analysis::TokenStream* tokenStream(const TCHAR* fieldName, CL_NS(util)::Reader* reader);
+	virtual lucene::analysis::TokenStream *tokenStream(const TCHAR *fieldName, CL_NS(util)::BufferedReader *reader);
 };
 
 #endif
diff --git a/ECtools/zarafa-search/ECIndexDB.cpp b/ECtools/zarafa-search/ECIndexDB.cpp
index 3b6533f..a7dd8fc 100644
--- a/ECtools/zarafa-search/ECIndexDB.cpp
+++ b/ECtools/zarafa-search/ECIndexDB.cpp
@@ -69,7 +69,7 @@
 #include <string>
 #include <algorithm>
 
-#include <CLucene/util/Reader.h>
+#include <CLucene/util/CLStreams.h>
 
 using namespace kyotocabinet;
 
@@ -314,7 +314,7 @@ HRESULT ECIndexDB::AddTerm(folderid_t folder, docid_t doc, fieldid_t field, unsi
         unsigned int len;
         unsigned int keylen;
         
-        lucene::util::StringReader reader(wstrTerm.c_str());
+        CL_NS(util)::StringReader reader(wstrTerm.c_str());
         
         stream = m_lpAnalyzer->tokenStream(L"", &reader);
         
